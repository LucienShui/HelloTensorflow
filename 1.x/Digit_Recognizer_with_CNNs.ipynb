{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Digit Recognizer with CNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "plR81b6ECtBc",
        "colab_type": "code",
        "outputId": "33b71924-ed65-4af0-cf62-8465dcbc9c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive\n",
        "drive.mount(\"/google_drive\")\n",
        "!ln -s /google_drive/My\\ Drive/datasets ~/datasets\n",
        "!ls ~/datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /google_drive; to attempt to forcibly remount, call drive.mount(\"/google_drive\", force_remount=True).\n",
            "ln: failed to create symbolic link '/root/datasets/datasets': Function not implemented\n",
            "digit-recognizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpbgIUV6D59V",
        "colab_type": "code",
        "outputId": "d18eaec8-79b5-4dad-871c-a4da80c75891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# tensorflow version 1.15\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_data_file = \"~/datasets/digit-recognizer/train.csv\"\n",
        "kaggle_test_data_file = \"~/datasets/digit-recognizer/test.csv\"\n",
        "kaggle_submit_file = \"~/datasets/digit-recognizer/result.csv\"\n",
        "\n",
        "raw_dataset = pd.read_csv(train_data_file, sep=\",\").values\n",
        "raw_kaggle_test_dataset = pd.read_csv(kaggle_test_data_file, sep=\",\").values\n",
        "\n",
        "total_size = raw_dataset.shape[0]\n",
        "split_point = [total_size * 6 // 10, total_size * 8 // 10]\n",
        "\n",
        "raw_train_dataset = raw_dataset[: split_point[0]]\n",
        "raw_validate_dataset = raw_dataset[split_point[0]: split_point[1]]\n",
        "raw_test_dataset = raw_dataset[split_point[1]:]\n",
        "\n",
        "\n",
        "def dense2one_hot(label_dense: np.ndarray, classes_count: int) -> np.ndarray:\n",
        "    num_label = label_dense.shape[0]\n",
        "    index_offset = np.arange(num_label) * classes_count\n",
        "    label_one_hot = np.zeros(shape=[num_label, classes_count], dtype=np.int)\n",
        "    label_one_hot.flat[index_offset + label_dense.ravel()] = 1\n",
        "    return label_one_hot\n",
        "\n",
        "\n",
        "def parse_dataset(dataset: np.ndarray) -> (np.ndarray, np.ndarray):\n",
        "    label = dataset[:, : 1].astype(np.int)\n",
        "    classes_count = np.unique(label).shape[0]\n",
        "    return dataset[:, 1:].astype(np.float32).reshape(-1, 28, 28, 1) / 255.0, dense2one_hot(label, classes_count).astype(np.float32)\n",
        "\n",
        "\n",
        "datasets = {\n",
        "    \"train\": {},\n",
        "    \"validation\": {},\n",
        "    \"test\": {}\n",
        "}\n",
        "\n",
        "datasets[\"train\"][\"input\"], datasets[\"train\"][\"label\"] = parse_dataset(raw_train_dataset)\n",
        "datasets[\"validation\"][\"input\"], datasets[\"validation\"][\"label\"] = parse_dataset(raw_validate_dataset)\n",
        "datasets[\"test\"][\"input\"], datasets[\"test\"][\"label\"] = parse_dataset(raw_test_dataset)\n",
        "\n",
        "for key in [\"train\", \"validation\", \"test\"]:\n",
        "    print(\"{} -> input: {}, label: {}\".format(key, datasets[key][\"input\"].shape, datasets[key][\"label\"].shape))\n",
        "\n",
        "\n",
        "def plot_digit(pixels):\n",
        "    plt.imshow(pixels.reshape(28, 28))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_digit(datasets[\"test\"][\"input\"][0, :])\n",
        "\n",
        "session = tf.Session()\n",
        "\n",
        "INPUT = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1])\n",
        "LABEL = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
        "\n",
        "previous_output = INPUT\n",
        "\n",
        "def create_network(num):\n",
        "    global previous_output\n",
        "    _weight = tf.get_variable(\"weight\", shape=[5, 5, 1, num], dtype=tf.float32,\n",
        "                                initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "    _bias = tf.get_variable(\"bias\", shape=[num], dtype=tf.float32,\n",
        "                            initializer=tf.constant_initializer(value=0.1))\n",
        "    conv = tf.nn.conv2d(previous_output, _weight, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "    active = tf.nn.relu(tf.add(conv, _bias))\n",
        "    previous_output = tf.nn.max_pool(active, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "for i in range(2):\n",
        "    with tf.variable_scope(\"conv_%d\" % i):\n",
        "        create_network(32 << i)\n",
        "\n",
        "with tf.variable_scope(\"fc_0\"):\n",
        "    flatten = tf.reshape(previous_output, [-1, 7 * 7 * 64])\n",
        "    weight = tf.get_variable(\"weight\", shape=[7 * 7 * 64, 1024], dtype=tf.float32,\n",
        "                                initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "    bias = tf.get_variable(\"bias\", shape=[1024], dtype=tf.float32,\n",
        "                            initializer=tf.constant_initializer(value=0.1))\n",
        "    previous_output = tf.nn.relu(tf.add(tf.matmul(flatten, weight), bias))\n",
        "\n",
        "# dropout\n",
        "rate = tf.placeholder(dtype=tf.float32)\n",
        "previous_output = tf.nn.dropout(previous_output, rate=rate)\n",
        "\n",
        "with tf.variable_scope(\"fc_1\"):\n",
        "    weight = tf.get_variable(\"weight\", shape=[1024, 10], dtype=tf.float32,\n",
        "                                initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "    bias = tf.get_variable(\"bias\", shape=[10], dtype=tf.float32, initializer=tf.constant_initializer(value=0.1))\n",
        "    previous_output = tf.nn.softmax(tf.add(tf.matmul(previous_output, weight), bias))\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(LABEL * tf.log(previous_output))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(previous_output, 1), tf.argmax(LABEL, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "TRAIN_SIZE = datasets['train']['input'].shape[0]\n",
        "BATCH_SIZE = 32\n",
        "EPOCH = 8\n",
        "TRAIN_STEPS = TRAIN_SIZE // BATCH_SIZE\n",
        "\n",
        "print(\"TRAIN_SIZE = {}, BATCH_SIZE = {}, EPOCH = {}, TRAIN_STEPS = {}\".\n",
        "        format(TRAIN_SIZE, BATCH_SIZE, EPOCH, TRAIN_STEPS))\n",
        "\n",
        "session.run(tf.global_variables_initializer())\n",
        "session.graph.finalize()\n",
        "summary_writer = tf.compat.v1.summary.FileWriter(\"./log/\", session.graph)\n",
        "\n",
        "for i in range(EPOCH):\n",
        "    np.random.shuffle(raw_train_dataset)\n",
        "    input_data, label_data = parse_dataset(raw_train_dataset)\n",
        "\n",
        "    for j in range(TRAIN_STEPS):\n",
        "        lower = j * BATCH_SIZE\n",
        "        upper = (j + 1) * BATCH_SIZE\n",
        "        batch_input = input_data[lower: upper]\n",
        "        batch_label = label_data[lower: upper]\n",
        "\n",
        "        session.run(train_step, {\n",
        "            INPUT: batch_input,\n",
        "            LABEL: batch_label,\n",
        "            rate: 0.5\n",
        "        })\n",
        "\n",
        "    if (i + 1) % 2 == 0:\n",
        "        train_acc, train_cost = session.run([accuracy, cross_entropy], {\n",
        "            INPUT: input_data,\n",
        "            LABEL: label_data,\n",
        "            rate: 0.0\n",
        "        })\n",
        "\n",
        "        test_acc, test_cost = session.run([accuracy, cross_entropy], {\n",
        "            INPUT: datasets[\"test\"][\"input\"],\n",
        "            LABEL: datasets[\"test\"][\"label\"],\n",
        "            rate: 0.0\n",
        "        })\n",
        "        print(\"epoch = %2d, train cost = %g, train accuracy = %g, test cost = %g, test accuracy = %g\" % (\n",
        "            i + 1, train_cost, train_acc, test_cost, test_acc))\n",
        "\n",
        "validate_acc, validate_cost = session.run([accuracy, cross_entropy], {\n",
        "    INPUT: datasets[\"validation\"][\"input\"],\n",
        "    LABEL: datasets[\"validation\"][\"label\"],\n",
        "    rate: 0.0\n",
        "})\n",
        "\n",
        "print(\"finally: validation cost = %g, validation accuracy = %g\" % (validate_cost, validate_acc))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train -> input: (25200, 28, 28, 1), label: (25200, 10)\n",
            "validation -> input: (8400, 28, 28, 1), label: (8400, 10)\n",
            "test -> input: (8400, 28, 28, 1), label: (8400, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg4EQdiBIAg7EARhB4L4fxFKWUKkHJ6eAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN_SIZE = 25200, BATCH_SIZE = 32, EPOCH = 8, TRAIN_STEPS = 787\n",
            "epoch =  2, train cost = 4373.63, train accuracy = 0.950794, test cost = 1434.05, test accuracy = 0.95119\n",
            "epoch =  4, train cost = 2569.11, train accuracy = 0.971389, test cost = 900.897, test accuracy = 0.966667\n",
            "epoch =  6, train cost = 1729.22, train accuracy = 0.979048, test cost = 626.667, test accuracy = 0.977143\n",
            "epoch =  8, train cost = 1208.02, train accuracy = 0.985556, test cost = 490.054, test accuracy = 0.980595\n",
            "finally: validation cost = 552.378, validation accuracy = 0.980952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUbJmPCm_EcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_test_dataset = raw_kaggle_test_dataset.astype(np.float32).reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "prediction = session.run(previous_output, {\n",
        "    INPUT: kaggle_test_dataset,\n",
        "    rate: 0.0\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u33oR5z8FL_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_test = np.argmax(prediction, axis=1)\n",
        "result = pd.concat([pd.Series(range(1, label_test.shape[0] + 1), name=\"ImageId\"), pd.Series(label_test, name=\"Label\")], axis = 1)\n",
        "result.head()\n",
        "result.to_csv(kaggle_submit_file, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Digit Recognizer with CNNs.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "plR81b6ECtBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "258f79c6-848c-469c-f312-954fb21ac4d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/google_drive\")\n",
        "!ln -s /google_drive/My\\ Drive/datasets ~/datasets\n",
        "!ls ~/datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /google_drive\n",
            "digit-recognizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpbgIUV6D59V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "f4c5fc26-b20e-47fd-f70e-74054ed75c5e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_data_file = \"~/datasets/digit-recognizer/train.csv\"\n",
        "kaggle_submit_data_file = \"~/datasets/digit-recognizer/test.csv\"\n",
        "\n",
        "raw_dataset = pd.read_csv(train_data_file, sep=\",\").values\n",
        "raw_kaggle_submit_dataset = pd.read_csv(kaggle_submit_data_file, sep=\",\").values\n",
        "\n",
        "total_size = raw_dataset.shape[0]\n",
        "split_point = [total_size * 6 // 10, total_size * 8 // 10]\n",
        "\n",
        "raw_train_dataset = raw_dataset[: split_point[0]]\n",
        "raw_validate_dataset = raw_dataset[split_point[0]: split_point[1]]\n",
        "raw_test_dataset = raw_dataset[split_point[1]:]\n",
        "\n",
        "\n",
        "def dense2one_hot(label_dense: np.ndarray, classes_count: int) -> np.ndarray:\n",
        "    num_label = label_dense.shape[0]\n",
        "    index_offset = np.arange(num_label) * classes_count\n",
        "    label_one_hot = np.zeros(shape=[num_label, classes_count], dtype=np.int)\n",
        "    label_one_hot.flat[index_offset + label_dense.ravel()] = 1\n",
        "    return label_one_hot\n",
        "\n",
        "\n",
        "def parse_dataset(dataset: np.ndarray) -> (np.ndarray, np.ndarray):\n",
        "    label = dataset[:, : 1].astype(np.int)\n",
        "    classes_count = np.unique(label).shape[0]\n",
        "    return dataset[:, 1:].astype(np.float32).reshape(-1, 28, 28, 1) / 255.0, dense2one_hot(label, classes_count).astype(np.float32)\n",
        "\n",
        "\n",
        "datasets = {\n",
        "    \"train\": {},\n",
        "    \"validation\": {},\n",
        "    \"test\": {}\n",
        "}\n",
        "\n",
        "datasets[\"train\"][\"input\"], datasets[\"train\"][\"label\"] = parse_dataset(raw_train_dataset)\n",
        "datasets[\"validation\"][\"input\"], datasets[\"validation\"][\"label\"] = parse_dataset(raw_validate_dataset)\n",
        "datasets[\"test\"][\"input\"], datasets[\"test\"][\"label\"] = parse_dataset(raw_test_dataset)\n",
        "\n",
        "for key in [\"train\", \"validation\", \"test\"]:\n",
        "    print(\"{} -> input: {}, label: {}\".format(key, datasets[key][\"input\"].shape, datasets[key][\"label\"].shape))\n",
        "\n",
        "\n",
        "def plot_digit(pixels):\n",
        "    plt.imshow(pixels.reshape(28, 28))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_digit(datasets[\"test\"][\"input\"][0, :])\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    INPUT = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1])\n",
        "    LABEL = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
        "\n",
        "    previous_output = INPUT\n",
        "\n",
        "    def create_network(num):\n",
        "        global previous_output\n",
        "        _weight = tf.get_variable(\"weight\", shape=[5, 5, 1, num], dtype=tf.float32,\n",
        "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        _bias = tf.get_variable(\"bias\", shape=[num], dtype=tf.float32,\n",
        "                                initializer=tf.constant_initializer(value=0.1))\n",
        "        conv = tf.nn.conv2d(previous_output, _weight, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        active = tf.nn.relu(tf.add(conv, _bias))\n",
        "        previous_output = tf.nn.max_pool(active, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "    for i in range(2):\n",
        "        with tf.variable_scope(\"conv_%d\" % i):\n",
        "            create_network(32 << i)\n",
        "\n",
        "    with tf.variable_scope(\"fc_0\"):\n",
        "        flatten = tf.reshape(previous_output, [-1, 7 * 7 * 64])\n",
        "        weight = tf.get_variable(\"weight\", shape=[7 * 7 * 64, 1024], dtype=tf.float32,\n",
        "                                 initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        bias = tf.get_variable(\"bias\", shape=[1024], dtype=tf.float32,\n",
        "                               initializer=tf.constant_initializer(value=0.1))\n",
        "        previous_output = tf.nn.relu(tf.add(tf.matmul(flatten, weight), bias))\n",
        "\n",
        "    # dropout\n",
        "    rate = tf.placeholder(dtype=tf.float32)\n",
        "    previous_output = tf.nn.dropout(previous_output, rate=rate)\n",
        "\n",
        "    with tf.variable_scope(\"fc_1\"):\n",
        "        weight = tf.get_variable(\"weight\", shape=[1024, 10], dtype=tf.float32,\n",
        "                                 initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "        bias = tf.get_variable(\"bias\", shape=[10], dtype=tf.float32, initializer=tf.constant_initializer(value=0.1))\n",
        "        previous_output = tf.nn.softmax(tf.add(tf.matmul(previous_output, weight), bias))\n",
        "\n",
        "    cross_entropy = -tf.reduce_sum(LABEL * tf.log(previous_output))\n",
        "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(previous_output, 1), tf.argmax(LABEL, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    TRAIN_SIZE = datasets['train']['input'].shape[0]\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCH = 8\n",
        "    TRAIN_STEPS = TRAIN_SIZE // BATCH_SIZE\n",
        "\n",
        "    print(\"TRAIN_SIZE = {}, BATCH_SIZE = {}, EPOCH = {}, TRAIN_STEPS = {}\".\n",
        "          format(TRAIN_SIZE, BATCH_SIZE, EPOCH, TRAIN_STEPS))\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        session.graph.finalize()\n",
        "        summary_writer = tf.compat.v1.summary.FileWriter(\"./log/\", session.graph)\n",
        "\n",
        "        for i in range(EPOCH):\n",
        "            np.random.shuffle(raw_train_dataset)\n",
        "            input_data, label_data = parse_dataset(raw_train_dataset)\n",
        "\n",
        "            for j in range(TRAIN_STEPS):\n",
        "                lower = j * BATCH_SIZE\n",
        "                upper = (j + 1) * BATCH_SIZE\n",
        "                batch_input = input_data[lower: upper]\n",
        "                batch_label = label_data[lower: upper]\n",
        "\n",
        "                session.run(train_step, {\n",
        "                    INPUT: batch_input,\n",
        "                    LABEL: batch_label,\n",
        "                    rate: 0.5\n",
        "                })\n",
        "\n",
        "            if (i + 1) % 2 == 0:\n",
        "                train_acc, train_cost = session.run([accuracy, cross_entropy], {\n",
        "                    INPUT: input_data,\n",
        "                    LABEL: label_data,\n",
        "                    rate: 0.0\n",
        "                })\n",
        "\n",
        "                test_acc, test_cost = session.run([accuracy, cross_entropy], {\n",
        "                    INPUT: datasets[\"test\"][\"input\"],\n",
        "                    LABEL: datasets[\"test\"][\"label\"],\n",
        "                    rate: 0.0\n",
        "                })\n",
        "                print(\"epoch = %2d, train cost = %g, train accuracy = %g, test cost = %g, test accuracy = %g\" % (\n",
        "                    i + 1, train_cost, train_acc, test_cost, test_acc))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train -> input: (25200, 28, 28, 1), label: (25200, 10)\n",
            "validation -> input: (8400, 28, 28, 1), label: (8400, 10)\n",
            "test -> input: (8400, 28, 28, 1), label: (8400, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADtNJREFUeJzt3X+QXXV5x/HPk7gEmh/kByaNSdpg\nmiAx0qjbxGpQNGAjYhP+EEg7mo7WUAe0CmVkcKZg2z8YW3GUUdoVUoNFREaR2KEFumPFIE2y0DQh\nJCSIcZJ0k4ChJlAIu5unf+yJXcKe773ce+49Z/O8XzM7e+95zrnn4ZLPnnvP997zNXcXgHhGld0A\ngHIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQb2unTs7xcb4qRrbzl0CobykF/SyH7V61m0q\n/Ga2TNJXJI2WdKu735ha/1SN1WJb2swuASRs8O661234Zb+ZjZb0NUkfkDRf0kozm9/o4wFor2be\n8y+S9JS7P+3uL0v6jqTlxbQFoNWaCf8MSXuG3N+bLXsFM1ttZj1m1tOno03sDkCRWn6239273L3T\n3Ts7NKbVuwNQp2bCv0/SrCH3Z2bLAIwAzYR/k6S5ZnammZ0i6TJJ64ppC0CrNTzU5+79ZnalpPs1\nONS3xt23FdYZgJZqapzf3e+TdF9BvQBoIz7eCwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQbZ2iG8MbPfH0ZN0m\nTUzW+94wKbfW+67fSG77hi/+NFmv1duTN78xWd/xvluT9VZavvNDuTX/wyPJbY8dSddPBhz5gaAI\nPxAU4QeCIvxAUIQfCIrwA0ERfiCopsb5zWy3pCOSBiT1u3tnEU2dbOztb07Wt1+eHovf+cG/T9aP\n6VhurXPjquS2L120KFkf/xd7kvUdc9Pj+I8cHZ1bWzymL7lts+6d98Pc2nvv/nBy2wl/3JGsD/zy\nUEM9VUkRH/J5r7s/W8DjAGgjXvYDQTUbfpf0gJk9amari2gIQHs0+7J/ibvvM7Opkh40sx3u/tDQ\nFbI/Cqsl6VSl39sCaJ+mjvzuvi/7fVDSPZJedfbI3bvcvdPdOzs0ppndAShQw+E3s7FmNv74bUnv\nl/R4UY0BaK1mXvZPk3SPmR1/nG+7+78W0hWAljN3b9vOJthkX2xL27a/qjh3y0vJ+jVTtibro2q8\nQEuN87/vs59KbjuxZ3+yPnD62GT9yNzxyfr4Xfnfi6+17aGz0//dP/7Tv03WJ406NbeWes4k6c0/\n/kSyPuePNifrZdng3Trsh6yedRnqA4Ii/EBQhB8IivADQRF+ICjCDwTFpbvb4PYn0l+bvebc9FDf\nswMvJuvv/JfP5tbO7t6Z3La/ya+mjvvPdD01kFxr23E19v2R+z+ZrP/Bretza1dMejK57ccWPJKs\nP/ybs5P1/v0HkvUq4MgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzt8GH52/santn+ybkKzPu3xT\nbm2gqT1X3H9sSZZvXn9+bu2KD6XH+a+ekr4uza4fTE3WDyxLT20+8D+/StbbgSM/EBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwTFOH8Bjlz6jmT9c1O+VuMR0n+D9/enx4wxvLOvzR/L/8Litye3/cLU9MUG\numb9e7K+YuLFyboY5wdQFsIPBEX4gaAIPxAU4QeCIvxAUIQfCKrmOL+ZrZF0kaSD7r4gWzZZ0l2S\nZkvaLekSd3+udW1WW+8F/cl6remga7n+7suS9dlKX2M+qtR35tf9/C3Jba+f+mhzO/fUjAXVUM+R\n/5uSlp2w7FpJ3e4+V1J3dh/ACFIz/O7+kKQTp3VZLmltdnutpBUF9wWgxRp9zz/N3Xuz2/slTSuo\nHwBt0vQJP3d3JaZkM7PVZtZjZj19Otrs7gAUpNHwHzCz6ZKU/T6Yt6K7d7l7p7t3dmhMg7sDULRG\nw79O0qrs9ipJ9xbTDoB2qRl+M7tT0iOSzjKzvWb2cUk3SrrAzHZJOj+7D2AEqTnO7+4rc0pLC+6l\n0kad86bc2l1Lb2npvufceeJgyyud1NfmR8vwCT8gKMIPBEX4gaAIPxAU4QeCIvxAUFy6u079p5+W\nW/vdU5p77K8+lz+MKEkD29LTSWN4o8aPz639/ozdLd33U6tnJuuzP7+npfuvB0d+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwiKcf4K+Pr69Lej52ljmzo5uRxasSC39oOZX23pvud8u/pfw+bIDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBMc5fp/1X5U81Noq/oZV0cEn+1OnN/j97duDFZN0Ov9DU47cD/2qB\noAg/EBThB4Ii/EBQhB8IivADQRF+IKia4/xmtkbSRZIOuvuCbNkNkj4h6Zlstevc/b5WNdkOoxbO\nT9avOfuB3NoxHWtq3zPvt6a2Rw7Pf16b/X92/qbLk/WZe7Y19fjtUM+R/5uSlg2z/MvuvjD7GdHB\nByKqGX53f0hS+rIkAEacZt7zX2lmW8xsjZlNKqwjAG3RaPhvkTRH0kJJvZK+lLeima02sx4z6+lT\n/ufjAbRXQ+F39wPuPuDuxyR9Q9KixLpd7t7p7p0dGtNonwAK1lD4zWz6kLsXS3q8mHYAtEs9Q313\nSjpP0hlmtlfS9ZLOM7OFklzSbknpcQ8AlVMz/O6+cpjFt7Wgl1Lt+LNxyfql43tbtu8Jj/13sp7/\nrXSgcXzCDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+7GSeusefta9th9Oye07LHbhSM/EBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwTFOD9GrL3XvTNZ33zWzbm15i7cLc3+5/QU3SMBR34gKMIPBEX4gaAIPxAU\n4QeCIvxAUIQfCIpx/sy0n6T/Dh66MH+qsTNGn9bUvrf/9euT9bkf3dPU41fVwHlvS9Zf95cHkvXU\nOL4kddjo3Nqvjr2c3HbRP16VrM9++JFkfSTgyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZm7p1cw\nmyXpdknTJLmkLnf/iplNlnSXpNmSdku6xN2fSz3WBJvsi21pAW23386u38ut7fjg11u6786Nq5L1\n558Zm1v7nW+1doLv/Vflf/5Bktwtt3bTOd9Nbvue0/63oZ6OG5U4tl36s2XJbV949zNN7bssG7xb\nh/1Q/pM+RD1H/n5JV7v7fEnvkHSFmc2XdK2kbnefK6k7uw9ghKgZfnfvdffHsttHJG2XNEPScklr\ns9XWSlrRqiYBFO81vec3s9mS3ippg6Rp7t6blfZr8G0BgBGi7vCb2ThJ35P0GXc/PLTmgycOhj15\nYGarzazHzHr6lH5/CKB96gq/mXVoMPh3uPv3s8UHzGx6Vp8u6eBw27p7l7t3untnh8YU0TOAAtQM\nv5mZpNskbXf3m4aU1kk6fhp6laR7i28PQKvUM9S3RNJPJG3V/1/x+DoNvu//rqTfkvQLDQ71HUo9\n1kge6ht1zptya+es3ZHc9q+mbmpu3zX+Rh9r+kLUjatybwv+6dO5tXn/0Jtbk6T+p3cX3E17vJah\nvprf53f39ZLyHmxkJhkAn/ADoiL8QFCEHwiK8ANBEX4gKMIPBFVznL9II3mcP2X0lMnJ+uE7Jibr\n3W+5K1mv8lh6M7396MVxyW0/fffHkvVa02Tbw5uT9ZNR0V/pBXASIvxAUIQfCIrwA0ERfiAowg8E\nRfiBoJiiuwADv0xexkDjP9yXrL9n+aeS9XOv2pCs/820jcl6K8374SeT9Zn35w85j//pz5Pbnnlg\n5E+DXWUc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKL7PD5xE+D4/gJoIPxAU4QeCIvxAUIQfCIrw\nA0ERfiComuE3s1lm9iMze8LMtpnZn2fLbzCzfWa2Ofu5sPXtAihKPRfz6Jd0tbs/ZmbjJT1qZg9m\ntS+7+9+1rj0ArVIz/O7eK6k3u33EzLZLmtHqxgC01mt6z29msyW9VdLx60pdaWZbzGyNmU3K2Wa1\nmfWYWU+fjjbVLIDi1B1+Mxsn6XuSPuPuhyXdImmOpIUafGXwpeG2c/cud+90984OjSmgZQBFqCv8\nZtahweDf4e7flyR3P+DuA+5+TNI3JC1qXZsAilbP2X6TdJuk7e5+05Dl04esdrGkx4tvD0Cr1HO2\n/12SPiJpq5kdn/P4OkkrzWyhJJe0W9LlLekQQEvUc7Z/vaThvh98X/HtAGgXPuEHBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqq1TdJvZM5J+MWTRGZKebVsD\nr01Ve6tqXxK9NarI3n7b3V9fz4ptDf+rdm7W4+6dpTWQUNXeqtqXRG+NKqs3XvYDQRF+IKiyw99V\n8v5TqtpbVfuS6K1RpfRW6nt+AOUp+8gPoCSlhN/MlpnZk2b2lJldW0YPecxst5ltzWYe7im5lzVm\ndtDMHh+ybLKZPWhmu7Lfw06TVlJvlZi5OTGzdKnPXdVmvG77y34zGy1pp6QLJO2VtEnSSnd/oq2N\n5DCz3ZI63b30MWEze7ek5yXd7u4LsmVflHTI3W/M/nBOcvfPVaS3GyQ9X/bMzdmEMtOHziwtaYWk\nP1GJz12ir0tUwvNWxpF/kaSn3P1pd39Z0nckLS+hj8pz94ckHTph8XJJa7PbazX4j6ftcnqrBHfv\ndffHsttHJB2fWbrU5y7RVynKCP8MSXuG3N+rak357ZIeMLNHzWx12c0MY1o2bbok7Zc0rcxmhlFz\n5uZ2OmFm6co8d43MeF00Tvi92hJ3f5ukD0i6Int5W0k++J6tSsM1dc3c3C7DzCz9a2U+d43OeF20\nMsK/T9KsIfdnZssqwd33Zb8PSrpH1Zt9+MDxSVKz3wdL7ufXqjRz83AzS6sCz12VZrwuI/ybJM01\nszPN7BRJl0laV0Ifr2JmY7MTMTKzsZLer+rNPrxO0qrs9ipJ95bYyytUZebmvJmlVfJzV7kZr929\n7T+SLtTgGf+fSfp8GT3k9PVGSf+V/WwruzdJd2rwZWCfBs+NfFzSFEndknZJ+jdJkyvU27ckbZW0\nRYNBm15Sb0s0+JJ+i6TN2c+FZT93ib5Ked74hB8QFCf8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8E9X9UypT+dqH4+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN_SIZE = 25200, BATCH_SIZE = 32, EPOCH = 8, TRAIN_STEPS = 787\n",
            "epoch =  2, train cost = 4269.11, train accuracy = 0.951746, test cost = 1421.91, test accuracy = 0.952381\n",
            "epoch =  4, train cost = 2623.45, train accuracy = 0.969921, test cost = 926.839, test accuracy = 0.96869\n",
            "epoch =  6, train cost = 1735.5, train accuracy = 0.980357, test cost = 664.912, test accuracy = 0.976548\n",
            "epoch =  8, train cost = 1234.52, train accuracy = 0.985913, test cost = 515.617, test accuracy = 0.980476\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}